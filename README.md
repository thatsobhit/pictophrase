# ğŸ§  PictoPhrase: Smart Image Captioning with Voice

**PictoPhrase** is a smart assistive technology project designed to generate human-like captions for images using deep learning, and read them aloud using text-to-speech (TTS). It empowers users with visual or speech impairments by providing meaningful image interpretations and audio feedback.

---

## ğŸš€ Features
- ğŸ–¼ï¸ **Image Feature Extraction** using **InceptionV3** CNN
- âœï¸ **Caption Generation** via LSTM-based decoder
- ğŸ”Š **Text-to-Speech (TTS)** using Google TTS (gTTS)
- ğŸ§± Modular architecture for easy customization and extension
- ğŸ§ª Ready-to-train notebook and inference code included

---

## ğŸ“‚ Project Structure
```bash
PictoPhrase/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocess.py          # Image preprocessing
â”‚   â”œâ”€â”€ feature_extractor.py   # CNN feature extraction
â”‚   â”œâ”€â”€ model.py               # LSTM caption model
â”‚   â”œâ”€â”€ inference.py           # Caption inference logic
â”‚   â”œâ”€â”€ utils.py               # Token utilities
â”‚   â””â”€â”€ speech.py              # Text-to-speech (TTS)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ captions.txt           # Captions file (for training)
â”‚   â”œâ”€â”€ tokenizer.pkl          # Saved tokenizer
â”‚   â””â”€â”€ sample_images/
â”‚       â””â”€â”€ sample.jpg         # Image to caption
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ training.ipynb         # Model training notebook
â”œâ”€â”€ model.h5                   # Trained captioning model (to be added)
â”œâ”€â”€ main.py                    # Main inference script
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ run.sh                     # Run the app (Linux/macOS)
â””â”€â”€ README.md                  # This file
